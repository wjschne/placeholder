<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8">
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta property="og:title" content="Practical Psychometrics: A Psychological Assessment Toolkit" />
<meta property="og:type" content="book" />


<meta property="og:description" content="This is a minimal example of using the bookdown package to write a book. The output format for this example is bookdown::gitbook." />
<meta name="github-repo" content="wjschne/psychtoolkit" />

<meta name="author" content="W. Joel Schneider" />

<meta name="date" content="2018-10-09" />

<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  TeX: { equationNumbers: { autoNumber: "AMS" } }
});
</script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-AMS_CHTML-full" type="text/javascript"></script>

<meta name="description" content="This is a minimal example of using the bookdown package to write a book. The output format for this example is bookdown::gitbook.">

<title>Practical Psychometrics: A Psychological Assessment Toolkit</title>

<link href="libs/tufte-css-2015.12.29/tufte.css" rel="stylesheet" />

<script type="text/x-mathjax-config">


MathJax.Hub.Config({
  TeX: {Augment: {
    Definitions: {macros: {xfrac: 'XFrac'}},
    Parse: {prototype: {
      XFrac: function (name) {
        var num = this.ParseArg(name);
        var den = this.ParseArg(name);
        this.Push(MathJax.ElementJax.mml.mfrac(num,den).With({bevelled: true}));
      }
    }}
  }}}
);


</script>


<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; position: absolute; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; }
pre.numberSource a.sourceLine:empty
  { position: absolute; }
pre.numberSource a.sourceLine::before
  { content: attr(data-line-number);
    position: absolute; left: -5em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<link rel="stylesheet" href="toc.css" type="text/css" />
<link rel="stylesheet" href="equity.css" type="text/css" />
<link rel="stylesheet" href="mycss.css" type="text/css" />

</head>

<body>



<div class="row">
<div class="col-sm-12">
<div id="TOC">
<ul>
<li><a href="index.html#preface">Preface</a></li>
<li><a href="intro.html#intro"><span class="toc-section-number">1</span> Introduction</a></li>
<li class="has-sub"><a href="variables.html#variables"><span class="toc-section-number">2</span> Variables</a><ul>
<li><a href="nominal.html#nominal"><span class="toc-section-number">2.1</span> Nominal Scales</a></li>
<li><a href="ordinal-scales.html#ordinal-scales"><span class="toc-section-number">2.2</span> Ordinal Scales</a></li>
<li><a href="interval-scales.html#interval-scales"><span class="toc-section-number">2.3</span> Interval Scales</a></li>
<li><a href="ratio-scales.html#ratio-scales"><span class="toc-section-number">2.4</span> Ratio Scales</a></li>
<li><a href="sec-DiscreteVsContinuous.html#sec:DiscreteVsContinuous"><span class="toc-section-number">2.5</span> Discrete vs.Â Continuous Variables</a></li>
</ul></li>
<li class="has-sub"><a href="distributions.html#distributions"><span class="toc-section-number">3</span> Distributions</a><ul>
<li class="has-sub"><a href="random-variables.html#random-variables"><span class="toc-section-number">3.1</span> Random Variables</a><ul>
<li><a href="random-variables.html#sets"><span class="toc-section-number">3.1.1</span> Sets</a></li>
<li><a href="random-variables.html#sec:SampleSpace"><span class="toc-section-number">3.1.2</span> Sample Spaces</a></li>
</ul></li>
<li><a href="sec-ProbabilityDistribution.html#sec:ProbabilityDistribution"><span class="toc-section-number">3.2</span> Probability Distributions</a></li>
<li class="has-sub"><a href="sec-DiscreteUniform.html#sec:DiscreteUniform"><span class="toc-section-number">3.3</span> Discrete Uniform Distributions</a><ul>
<li><a href="sec-DiscreteUniform.html#parameters-of-random-variables"><span class="toc-section-number">3.3.1</span> Parameters of Random Variables</a></li>
<li><a href="sec-DiscreteUniform.html#sec:pmf"><span class="toc-section-number">3.3.2</span> Probability Mass Functions</a></li>
<li><a href="sec-DiscreteUniform.html#sec:CumDist"><span class="toc-section-number">3.3.3</span> Cumulative Distribution Functions</a></li>
<li><a href="sec-DiscreteUniform.html#sec:Quantile"><span class="toc-section-number">3.3.4</span> Quantile functions</a></li>
<li><a href="sec-DiscreteUniform.html#generating-a-random-sample-in-r"><span class="toc-section-number">3.3.5</span> Generating a Random Sample in R</a></li>
</ul></li>
<li class="has-sub"><a href="sec-BernoulliDist.html#sec:BernoulliDist"><span class="toc-section-number">3.4</span> Bernoulli Distributions</a><ul>
<li><a href="sec-BernoulliDist.html#generating-a-random-sample-from-the-bernoulli-distribution"><span class="toc-section-number">3.4.1</span> Generating a Random Sample from the Bernoulli Distribution</a></li>
</ul></li>
<li class="has-sub"><a href="sec-binomial.html#sec:binomial"><span class="toc-section-number">3.5</span> Binomial Distributions</a><ul>
<li><a href="sec-binomial.html#clinical-applications-of-the-binomial-distribution"><span class="toc-section-number">3.5.1</span> Clinical Applications of the Binomial Distribution</a></li>
<li><a href="sec-binomial.html#graphing-the-binomial-distribution"><span class="toc-section-number">3.5.2</span> Graphing the binomial distribution</a></li>
</ul></li>
<li class="has-sub"><a href="poisson-distributions.html#poisson-distributions"><span class="toc-section-number">3.6</span> Poisson Distributions</a><ul>
<li><a href="poisson-distributions.html#a-clinical-application-of-the-the-poisson-distribution"><span class="toc-section-number">3.6.1</span> A clinical application of the the Poisson distribution</a></li>
</ul></li>
<li><a href="geometric-distributions.html#geometric-distributions"><span class="toc-section-number">3.7</span> Geometric Distributions}</a></li>
<li><a href="sec-pdf.html#sec:pdf"><span class="toc-section-number">3.8</span> Probability Density Functions</a></li>
<li class="has-sub"><a href="sec-Uniform.html#sec:Uniform"><span class="toc-section-number">3.9</span> Continuous Uniform Distributions</a><ul>
<li><a href="sec-Uniform.html#generating-random-samples-from-the-continuous-uniform-distribution"><span class="toc-section-number">3.9.1</span> Generating random samples from the continuous uniform distribution</a></li>
<li><a href="sec-Uniform.html#using-the-continuous-uniform-distribution-to-generate-random-samples-from-other-distributions"><span class="toc-section-number">3.9.2</span> Using the continuous uniform distribution to generate random samples from other distributions</a></li>
</ul></li>
<li class="has-sub"><a href="sec-normal.html#sec:normal"><span class="toc-section-number">3.10</span> Normal Distributions</a><ul>
<li><a href="sec-normal.html#notation-for-normal-variates"><span class="toc-section-number">3.10.1</span> Notation for Normal Variates</a></li>
</ul></li>
<li><a href="half-normal-distribution.html#half-normal-distribution"><span class="toc-section-number">3.11</span> Half-Normal Distribution</a></li>
</ul></li>
<li class="has-sub"><a href="descriptive-statistics.html#descriptive-statistics"><span class="toc-section-number">4</span> Descriptive Statistics</a><ul>
<li><a href="frequency-distribution-tables.html#frequency-distribution-tables"><span class="toc-section-number">4.1</span> Frequency Distribution Tables</a></li>
<li class="has-sub"><a href="central-tendencies.html#central-tendencies"><span class="toc-section-number">4.2</span> Central Tendencies</a><ul>
<li><a href="central-tendencies.html#mode"><span class="toc-section-number">4.2.1</span> Mode</a></li>
</ul></li>
<li><a href="expected-values.html#expected-values"><span class="toc-section-number">4.3</span> Expected Values</a></li>
</ul></li>
<li class="has-sub"><a href="notation.html#notation">Notation</a><ul>
<li><a href="random-variables-vectors-and-matrices.html#random-variables-vectors-and-matrices"><span class="toc-section-number">4.4</span> Random variables, vectors, and matrices</a></li>
<li><a href="sets-and-intervals.html#sets-and-intervals"><span class="toc-section-number">4.5</span> Sets and intervals</a></li>
<li><a href="summation.html#summation"><span class="toc-section-number">4.6</span> Summation</a></li>
<li><a href="other.html#other"><span class="toc-section-number">4.7</span> Other</a></li>
</ul></li>
<li class="has-sub"><a href="references.html#references">References</a><ul>
<li><a href="r-packages-used-in-this-book.html#r-packages-used-in-this-book">R packages used in this book</a></li>
</ul></li>
</ul>
</div>
</div>
</div>
<div class="row">
<div class="col-sm-12">
<div id="sec:normal" class="section level2">
<h2><span class="header-section-number">3.10</span> Normal Distributions</h2>
<p>
<span class="marginnote shownote">
<!--
<div class="figure">--><span id="fig:GaussImage"></span>
<img src="Carl_Friedrich_Gauss2.jpg" alt="Carl Friedrich Gauss (1777--1855)&lt;br&gt;[Image Credits](https://en.wikipedia.org/wiki/File:Carl_Friedrich_Gauss_1840_by_Jensen.jpg)" width="442"  />
<!--
<p class="caption marginnote">-->Figure 2.25: Carl Friedrich Gauss (1777â1855)<br><a href="https://en.wikipedia.org/wiki/File:Carl_Friedrich_Gauss_1840_by_Jensen.jpg">Image Credits</a><!--</p>-->
<!--</div>--></span>
</p>
<!-- \begin{equation*} -->
<!-- \boxed{ -->
<!-- \begin{array}{rccc} -->
<!-- \text{Sample Space:} & x &\in&[-\infty,\infty]\\ -->
<!-- \text{Mean:} & \mu&=&\frac{a+b}{2} \\ -->
<!-- \text{Variance:} & \sigma^2&=&\frac{(b-a)^2-1}{12} \\ -->
<!-- \text{Skewness:} & \gamma_1&=&0 \\ -->
<!-- \text{Kurtosis:} & \gamma_2&=&-\frac{6}{5} \\ -->
<!-- \text{Probability Density Function:} & f_X(x;a,b)&=&\frac{1}{b-a} \\ -->
<!-- \text{Cumulative Distribution Function:} & F_X(x;a,b)&=&\frac{x-a}{b-a} \\ -->
<!-- \end{array} -->
<!-- } -->
<!-- \end{equation*} -->
<p><!--
<caption>--><span class="marginnote shownote"><span id="tab:normalfeatures">Table 2.7: </span>Features of Normal Distributions</span><!--</caption>--></p>
<table>
<thead>
<tr class="header">
<th align="left">Feature</th>
<th align="left">Symbol</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Sample Space</td>
<td align="left"><span class="math inline">\(x \in [-\infty,\infty]\)</span></td>
</tr>
<tr class="even">
<td align="left">Mean</td>
<td align="left"><span class="math inline">\(\mu = \text{E}\left(X\right)\)</span></td>
</tr>
<tr class="odd">
<td align="left">Variance</td>
<td align="left"><span class="math inline">\(\sigma^2 = \text{E}\left(\left(X - \mu\right)^2\right)\)</span></td>
</tr>
<tr class="even">
<td align="left">Skewness</td>
<td align="left"><span class="math inline">\(\gamma_1 = 0\)</span></td>
</tr>
<tr class="odd">
<td align="left">Kurtosis</td>
<td align="left"><span class="math inline">\(\gamma_2 = 0\)</span></td>
</tr>
<tr class="even">
<td align="left">Probability Density Function</td>
<td align="left"><span class="math inline">\(f_X(x;\mu,\sigma^2) = \frac{1}{\sqrt{2 \pi \sigma ^ 2}} e^{-\frac{1}{2}\left(\frac{x-\mu}{\sigma}\right)^2}\)</span></td>
</tr>
<tr class="odd">
<td align="left">Cumulative Distribution Function</td>
<td align="left"><span class="math inline">\(F_X(x;\mu,\sigma^2) = \frac{1}{\sqrt{2\pi\sigma^2}} {\displaystyle \int_{-\infty}^{x} e ^ {-\frac{1}{2}\left(\frac{x-\mu}{\sigma}\right)^2}dx}\)</span></td>
</tr>
</tbody>
</table>
<p>The normal distribution is probably the most important distribution in statistics and in psychological assessment. In the absence of other information, assuming that an individual difference variable is normally distributed is a good bet. Not a sure bet, of course, but a good bet. Why? What is so special about the normal distribution? To get a sense of the answer to this question, consider what happens to the binomial distribution as the number of events (<span class="math inline">\(n\)</span>) increases. To make the example more concrete, letâs assume that we are tossing coins and counting the number of heads (<span class="math inline">\(p=0.5\)</span>). In FigureÂ <a href="sec-normal.html#fig:ManyCoins">2.26</a>, the first plot shows the probability mass function for the number of heads when there is a single coin (<span class="math inline">\(n=1\)</span>). In the second plot, <span class="math inline">\(n=2\)</span> coins. That is, if we flip 2 coins, there will be 0, 1, or 2 heads. In each subsequent plot, we double the number of coins that we flip simultaneously. Even with as few as 4 coins, the distribution begins to resemble the normal distribution, although the resemblance is very rough. With 128 coins, however, the resemblance is very close.</p>
<p>This resemblance to the normal distribution in the example is not coincidental to the fact that <span class="math inline">\(p=0.5\)</span>, making the binomial distribution symmetric. If <span class="math inline">\(p\)</span> is extreme (close to 0 or 1), the binomial distribution is assymetric. However, if <span class="math inline">\(n\)</span> is large enough, the binomial distribution eventually becomes very close to normal.</p>
<p>Many other distributions (e.g., Poisson, Studentâs T, F, and <span class="math inline">\(\chi^2\)</span>) have distinctive shapes under some conditions but approximate the normal distribution in others. Why? In the conditions in which non-normal distributions approximate the normal distribution, it is because, like in FigureÂ <a href="sec-normal.html#fig:ManyCoins">2.26</a>, many independent events are summed.</p>
<div class="figure fullwidth"><span id="fig:ManyCoins"></span>
<img src="toolkit_files/figure-html/ManyCoins-1.svg" alt="The binomial distribution begins to resemble the normal distribution when the number of events is large."  />
<p class="caption marginnote shownote">
Figure 2.26: The binomial distribution begins to resemble the normal distribution when the number of events is large.
</p>
</div>
<p>In the distribution in FigureÂ <a href="sec-binomial.html#fig:twocoin">2.12</a>, because there is a 50% chance of heads, <span class="math inline">\(p = 0.5\)</span>. Because there are two coins, <span class="math inline">\(n = 2\)</span>. We can use the <a href="sec-binomial.html#sec:binomial">binomial distributionâs probability mass function</a> to see how the shape of the distribution changes as we increase the number of coins tossed (FigureÂ <a href="sec-normal.html#fig:ManyCoins">2.26</a>).</p>
<p><img src="toolkit_files/figure-html/nearlynormal-1.svg"  /></p>
<div id="notation-for-normal-variates" class="section level3">
<h3><span class="header-section-number">3.10.1</span> Notation for Normal Variates</h3>
<p>Statisticians write about variables with normal distributions so often that a compact notation for specifying a normal variableâs parameters was useful to develop. There are several common variations to this notation, but I will use this one:</p>
<p><span class="math display">\[X \sim \mathcal{N}(\mu, \sigma^2)\]</span></p>
<ul>
<li><span class="math inline">\(X\)</span> is a random variable.</li>
<li><span class="math inline">\(\sim\)</span> means âis distributed as.â It can be applied to any kind of distribution, not just the normal distribution.</li>
<li><span class="math inline">\(\mathcal{N}\)</span> means that the variable has a normal distribution. Instead of <span class="math inline">\(\mathcal{N}\)</span>, the notation for a normal variable is often simply <span class="math inline">\(N\)</span>.</li>
<li><span class="math inline">\(\mu\)</span> is the mean.</li>
<li><span class="math inline">\(\sigma^2\)</span> is the variance.</li>
</ul>
<p>Many authors list the standard deviation <span class="math inline">\(\sigma\)</span> instead of the variance <span class="math inline">\(\sigma^2\)</span>. When I specify normal distribions with specific means and variances, I will avoid ambiguity by always showing the variance as the standard deviation squared. For example, a normal variate with a mean of 10 and a standard deviation of 3 will be written as <span class="math inline">\(X \sim \mathcal{N}(10,3^2)\)</span>.</p>
<div class="figure fullwidth"><span id="fig:PercentileContinuous"></span>
<img src="toolkit_files/figure-html/PercentileContinuous-1.svg" alt="Percentiles convert a distribution into a uniform distribution" width="1050"  />
<p class="caption marginnote shownote">
Figure 2.27: Percentiles convert a distribution into a uniform distribution
</p>
</div>
</div>
</div>
<p style="text-align: center;">
<a href="sec-Uniform.html"><button class="btn btn-default">Previous</button></a>
<a href="half-normal-distribution.html"><button class="btn btn-default">Next</button></a>
</p>
</div>
</div>



</body>
</html>
